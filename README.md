# OneFormer: One Transformer to Rule Universal Image Segmentation

CVPR 2023. [Paper] [Page] [Github]
Jitesh Jain, Jiachen Li, MangTik Chiu, Ali Hassani, Nikita Orlov, Humphrey Shig
SHI Labs | IIT Roorkee | Picsart AI Research (PAIR)
10 Nov 2022

![Untitled](./subpages/1.png)

### Abstract

ì§€ë‚œ ëª‡ ì‹­ ë…„ ë™ì•ˆ ì¥ë©´ íŒŒì‹±, panoptic segmentation, ê·¸ë¦¬ê³  ìµœê·¼ì˜ ìƒˆë¡œìš´ panoptic architecture ë“±ì„ í¬í•¨í•˜ì—¬ ì´ë¯¸ì§€ segmentationì„ í†µí•©í•˜ë ¤ëŠ” ì‹œë„ê°€ ìˆì—ˆë‹¤. ê³¼ê±°ì˜ ì•„í‚¤í…ì²˜ëŠ” semantic, instance, panoptic segmentation ê°ê°ì— ëŒ€í•´ ìµœìƒì˜ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ê°œë³„ì ìœ¼ë¡œ í›ˆë ¨ì´ í•„ìš”í–ˆë‹¤. ì§„ì •í•œ í†µí•© í”„ë ˆì„ì›Œí¬ëŠ” í•œ ë²ˆì˜ í›ˆë ¨ë§Œìœ¼ë¡œ ì„¸ ê°€ì§€ ì´ë¯¸ì§€ segmentation ì‘ì—… ëª¨ë‘ì—ì„œ SOTA(ìµœì²¨ë‹¨) ì„±ëŠ¥ì„ ë‹¬ì„±í•´ì•¼ í•  ê²ƒì´ë‹¤. ì´ë¥¼ ìœ„í•´, ìš°ë¦¬ëŠ” ë‹¨ì¼ ë‹¤ì¤‘ ì‘ì—… í›ˆë ¨ ë””ìì¸ìœ¼ë¡œ segmentationì„ í†µí•©í•˜ëŠ” ë³´í¸ì  ì´ë¯¸ì§€ segmentation í”„ë ˆì„ì›Œí¬ì¸ OneFormerë¥¼ ì œì•ˆí•œë‹¤. 

1. Semantic, instance, panoptic segmentation ê° ë„ë©”ì¸ì˜ ì‹¤ì œ ë°ì´í„°ì— ëŒ€í•´ ë‹¨ì¼ multi-task í›ˆë ¨ í”„ë¡œì„¸ìŠ¤ ë‚´ì—ì„œ í›ˆë ¨ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” task-conditioned joint training strategyë¥¼ ì œì•ˆí•œë‹¤
2. ëª¨ë¸ì´ ì£¼ì–´ì§„ ì‘ì—…ì— ë§ê²Œ ë™ì ìœ¼ë¡œ ì ì‘í•˜ë„ë¡ ì‘ì—… í† í°ì„ ë„ì…í•œë‹¤.
3. í›ˆë ¨ ì¤‘ ì‘ì—… ê°„ ë° í´ë˜ìŠ¤ ê°„ êµ¬ë¶„ì„ ëª…í™•íˆ í•˜ê¸° ìœ„í•´ query-text contrastive learningì„ ì‚¬ìš©í•œë‹¤. 

### [Keywords](./subpages/Keywords.md)

### [Evaluation Metrics](./subpages/Evaluation_Metrics.md)

# 1. Introduction

Panoptic Segmentation: í˜•íƒœê°€ ì—†ëŠ” background ì˜ì—­ì„ `stuff` , í˜•ëŒ€ê°€ ë¶„ëª…í•œ ê°ì²´ë¥¼ `thing` ìœ¼ë¡œ ì •ì˜í•˜ì—¬, ë‘ê°€ì§€ ëª¨ë‘ ê³ ë ¤í•˜ì—¬ ì‹ë³„.

ex)K-Net, MaskFormer, Mask2Former

Panoptic architectureë¥¼ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ì€ 3ê°€ì§€ segmentation ë°©ì‹ì— ì‚¬ìš©í•  ìˆ˜ ìˆê³ , ì„±ëŠ¥ì´ ë†’ë‹¤ëŠ” ì¥ì ì„ ê°€ì§€ê³  ìˆë‹¤.

ê·¸ë¦¬ê³ , ë‹¤ë¥¸ 2ê°€ì§€ ë°©ì‹ì€ ê°œë³„ë¡œ í›ˆë ¨í•˜ì—¬ ì‹œê°„ì´ ì†Œëª¨ë  ë¿ë”ëŸ¬, ëª¨ë¸ì˜ weightë„ ë‹¤ë¥¼ ê²ƒì´ë‹¤.

ê·¸ë˜ì„œ ë³¸ ì—°êµ¬ì—ì„œ OneFormer, multi-task universal image segmentation frameworkë¥¼ ì œì•ˆí•˜ê³ ì í•œë‹¤.

ì´ ê³¼ì •ì—ì„œ, ìš°ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í–ˆë‹¤.

1. ì™œ ì§€ê¸ˆê¹Œì§€ì˜ panoptic architectureëŠ” single training process ë˜ëŠ” 3ê°€ì§€ taskì— ëª¨ë‘ ì ìš©ë˜ì§€ ì•ŠëŠ”ê°€?
    
    ê·¸ë“¤ì˜ architectureì— task guidanceê°€ ì—†ê¸° ë•Œë¬¸ì´ë¼ê³  ì¶”ì¸¡í•œë‹¤. ë™ì‹œì— í•™ìŠµí•˜ê±°ë‚˜, ë‹¨ì¼ ëª¨ë¸ì—ì„œ í•™ìŠµí•  ë•Œ ì‘ì—… ê°„ ì°¨ì´ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì´ ì–´ë µê¸° ë•Œë¬¸ì´ë‹¤. ìš°ë¦¬ëŠ” ì´ë¥¼ task input token â€œthe task is {task}â€ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ˆì ì„ ë§ì¶˜ ì‘ì—…ì— ì¡°ê±´í™”í•˜ì—¬ ì‚¬ìš©í•œë‹¤. ì´ì— ë”°ë¼, ì´ ë‹¨ì¼ ëª¨ë¸ì€ í›ˆë ¨ì„ ìœ„í•´ task-guidedëœ architectureê°€ ë˜ê³ , ì¶”ë¡ ì„ ìœ„í•´ task-dynamicëœë‹¤.
    
    {panoptic, instance, semantic} ì‘ì—…ì„ ê· ì¼í•˜ê²Œ ìƒ˜í”Œë§í•˜ê³ , ê³µë™ í›ˆë ¨ ê³¼ì •ì—ì„œ í•´ë‹¹ ì‹¤ì œ ê°’(ground truth)ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì´ ì‘ì—…ì— ëŒ€í•œ í¸í–¥ì´ ì—†ë„ë¡ í•©ë‹ˆë‹¤. 
    
    Semantic, instance labelë¡œë¶€í„° panoptic annotationì„ ë„ì¶œí•˜ì—¬ í›ˆë ¨ì— ì‚¬ìš©í•œë‹¤. ì¦‰, í›ˆë ¨ ê³¼ì •ì—ì„œëŠ” panoptic dataë§Œ í•„ìš”í•˜ë‹¤. 
    
    ê³µë™ í›ˆë ¨ ì‹œê°„, ëª¨ë¸ ë§¤ê°œë³€ìˆ˜, ê·¸ë¦¬ê³  FLOPëŠ” ê¸°ì¡´ ë°©ë²•ë“¤ê³¼ ë¹„êµí•  ë•Œ ë¹„ìŠ·í•˜ì—¬ í›ˆë ¨ ì‹œê°„ê³¼ ì €ì¥ ìš”êµ¬ ì‚¬í•­ì„ ìµœëŒ€ 3ë°° ì¤„ì´ê³ , ì´ë¯¸ì§€ ì„¸ê·¸ë¨¼í…Œì´ì…˜ì„ ëœ ìì› ì§‘ì•½ì ì´ê³  ë” ì ‘ê·¼ ê°€ëŠ¥í•˜ê²Œ ë§Œë“ ë‹¤.
    
2. ì–´ë–»ê²Œ ë‹¨ì¼ ê³µë™ í›ˆë ¨ ê³¼ì •ì—ì„œ multi-task ëª¨ë¸ì´ task ê°„ ì°¨ì´, class ê°„ ì°¨ì´ë¥¼ ì˜ í•™ìŠµí•  ìˆ˜ ìˆëŠ”ê°€?
    
    ìš°ë¦¬ì˜ ì ‘ê·¼ë°©ì‹ì€ transformerë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ, query tokenì„ ì‚¬ìš©í•œ ë°©ì‹ì´ë‹¤. 
    
    ëª¨ë¸ì— ì‘ì—…ë³„ contextë¥¼ ì¶”ê°€í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì‘ì—… ì…ë ¥ì—ì„œ ì–»ì€ ì‘ì—… í† í°ì„ ë°˜ë³µí•˜ì—¬ ìš°ë¦¬ì˜ ì¿¼ë¦¬ë¥¼ ì´ˆê¸°í™”í•˜ê³ , ìƒ˜í”Œë§ëœ ì‘ì—…ì˜ ì‹¤ì œ ë ˆì´ë¸”ì—ì„œ íŒŒìƒëœ í…ìŠ¤íŠ¸ì™€ ì¿¼ë¦¬-í…ìŠ¤íŠ¸ contrastive lossë¥¼ ê³„ì‚°í•œë‹¤. ì¿¼ë¦¬ì— ëŒ€í•œ contrastive lossê°€ ëª¨ë¸ì„ ë” ì‘ì—…ì— ë¯¼ê°í•˜ê²Œ ì•ˆë‚´í•˜ëŠ” ë° ë„ì›€ì´ ë  ê²ƒì´ë¼ ì¶”ì¸¡í•œë‹¤. ë˜í•œ, ì´ëŠ” ì¹´í…Œê³ ë¦¬ ì˜ëª» ì˜ˆì¸¡ì„ ì–´ëŠ ì •ë„ ì¤„ì´ëŠ” ë° ë„ì›€ì´ ëœë‹¤. 
    

ì´ ëª¨ë¸ì€ ë‹¤ìŒê³¼ ê°™ì€ ê¸°ì—¬ë¥¼ í–ˆë‹¤.

- Single universal architecture: ë‹¨ì¼ ëª¨ë¸ ë° ë‹¨ì¼ ë°ì´í„° ì„¸íŠ¸ë¡œ í•œ ë²ˆë§Œ í•™ìŠµí•´ë„ ë˜ëŠ”, íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ”, ìµœì´ˆì˜ ë‹¤ì¤‘ ì‘ì—… ë²”ìš© ì´ë¯¸ì§€ ë¶„í•  í”„ë ˆì„ì›Œí¬
- Panoptic segmentationì˜ í†µí•© ëª©í‘œ ë‹¬ì„±
- í‘œì¤€ Swin-L Backboneì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ê³¼ ë¹„êµí•˜ì—¬ ì„¸ ê°€ì§€ segmentation ì‘ì—… ëª¨ë‘ì—ì„œ ìƒˆë¡œìš´ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ì„¤ì •í•˜ê³  ìƒˆë¡œìš´ ConvNeXt ë° DiNAT ë°±ë³¸ìœ¼ë¡œ í›¨ì”¬ ë” í–¥ìƒë˜ì—ˆë‹¤.

# 2. Related Work

## 2.1 Image Segmentation

MaskFormerëŠ” Semantic segmentation ë¶„ì•¼ë¥¼ mask classification ë¶„ì•¼ë¡œ ìµœì´ˆë¡œ ì·¨ê¸‰í–ˆì—ˆê³ , ë³¸ ë…¼ë¬¸ì—ì„œë„ ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì„ ê°€ì§€ê³  ìˆë‹¤.

ê¸°ì¡´ì˜ Instance segmentation ë¶„ì•¼ ë˜í•œ mask classification ë¶„ì•¼ë¡œ ê³µì‹í™”ë˜ì–´, 2ì§„ maskì™€ ê°ê°ì˜ maskì— ëŒ€í•œ class labelì„ ì˜ˆì¸¡í•œë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œë„ ì—­ì‹œ ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì„ ê°€ì§€ê³  ìˆë‹¤.

Panoptic segmentationì€ semanticê³¼ instance segmentationë¥¼ í†µí•©í•˜ê¸° ìœ„í•´ ì œì•ˆë˜ì—ˆì—ˆë‹¤. ìµœì´ˆëŠ” instanceì™€ semantic taskì˜ brachë“¤ì„ ë¶„ë¦¬í–ˆë˜ Panoptic-FPNì—ì„œ ì†Œê°œë˜ì—ˆìœ¼ë©°, transformer ê¸°ë°˜ì˜ architectureë¡œ ë°œì „í•´ì™”ë‹¤. í•˜ì§€ë§Œ ì•„ì§ê¹Œì§€ ì™„ì „í•œ í†µí•©ì„ ì´ë£¨ì§„ ëª»í–ˆê³ , ë³¸ ë…¼ë¬¸ì—ì„œ panoptic annotationë§Œì„ ì´ìš©í•˜ì—¬ í†µí•©í•˜ê³ ì í•œë‹¤.

## 2.2 Universal Image Segmentation

MaskFormer, Mask2Former, K-Net ì—ì„œ ì´ë¯¸ semantic, instance segmentationì—ì„œë„ ì˜ ì‘ë™í•˜ëŠ” panoptic segmentationì´ ë“±ì¥í•œ ë°” ìˆë‹¤.

K-Netì€ CNNì„ ì‚¬ìš©í•´ì„œ, ë™ì ìœ¼ë¡œ í•™ìŠµì´ ê°€ëŠ¥í•œ instance, semantic kernelì„ ì´ë¶„ë²• matchingì„ ì‚¬ìš©í–ˆë‹¤.

MaskFormerëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ë¡œ mask classifier ì—­í• ì„ í•œë‹¤. ì´ë¯¸ì§€ê°€ encoderë¡œ ê³µê¸‰ë˜ê³  decoderê°€ queryë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì œì•ˆì„ ìƒì„±í•˜ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ë²”ìœ„ì˜ ê°ì²´ ê°ì§€ì— ëŒ€í•œ DETRì˜ ë¦¬í¬ë°ì—ì„œ ì˜ê°ì„ ì–»ì—ˆë‹¤.

Mask2FormerëŠ” MaskFormerë¥¼ í•™ìŠµê°€ëŠ¥í•œ queryì™€ ì‚¬ìš©í•˜ê³ , decoderì— ë³€í˜•ê°€ëŠ¥í•œ multi-scaleì˜ attentionì„ ì‚¬ìš©í•˜ê³ , masked cross-attentionì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ë¥¸ ë‘ ëª¨ë¸ì˜ ì„±ëŠ¥ë³´ë‹¤ ì•ì„°ë‹¤.

í•˜ì§€ë§Œ, ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ê¸° ìœ„í•´ì„œ ê°ê°ì˜ taskì— ê°œë³„ì ì¸ í•™ìŠµì´ í•„ìš”í–ˆë‹¤.

## 2.3 Transformer-based Architectures

DETR ì´í›„ë¡œ, transformerì˜ encoder-decoder êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ object detectionì˜ ì„±ëŠ¥ì´ íš¨ê³¼ì ìœ¼ë¡œ ì¦ê°€í–ˆë‹¤.

Mask2FormerëŠ” transformer êµ¬ì¡°ê°€ image segmentation (+ mask classification) êµ¬ì¡°ì— ìœ ë¦¬í•˜ë‹¤ëŠ” ê²ƒì„ ì…ì¦í–ˆë‹¤.

ì¶”ê°€ì ìœ¼ë¡œ, ìš°ë¦¬ëŠ” task-guided queryì—ì„œ query-text contrastive lossë¥¼ ê³„ì‚°í•˜ëŠ” ê²ƒì´ ëª¨ë¸ì´ taskê°„ì˜ ì°¨ì´ë¥¼ í•™ìŠµí•˜ê³ , ëª¨ë¸ ì¶œë ¥ì˜ ì˜ëª»ëœ classificationì„ ì¤„ì¼ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ì…ì¦í–ˆë‹¤.

LMSegì—ì„œëŠ” multiple datasetì˜ ë¶„ë¥˜ì—ì„œ íŒŒìƒëœ textë¥¼ ì‚¬ìš©í•˜ì—¬ query-text contrastive lossë¥¼ ê³„ì‚°í•˜ê³ , multi-dataset segmentation ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ ì í–ˆë‹¤.

ë³¸ ì—°êµ¬ì—ì„œëŠ”, LMSegì™€ëŠ” ë‹¤ë¥´ê²Œ, multiple taskì— ì´ˆì ì„ ë§ì¶”ê³ , í›ˆë ¨ ë°ì´í„°ì…‹ì— ì¡´ì¬í•˜ëŠ” ground-truth labelì„ ì‚¬ìš©í•´ query-text contrastive lossë¥¼ ê³„ì‚°í•œë‹¤.

# 3. Method

OneFormerëŠ” ë‹¤ìŒ 2ê°€ì§€ì˜ inputì„ ê°€ì§„ë‹¤

- Image
- Task - â€œthe task is {task}â€ : {panoptic, instance, semantic}

![Untitled](./subpages/2.png)

OneFormerì˜ í•™ìŠµ ë°©ë²•

1. Backboneê³¼ pixel decoderë¥¼ ì‚¬ìš©í•´ Imageë¡œë¶€í„° multi-scale featureë¥¼ ì¶”ì¶œí•œë‹¤.
2. task inputì„ í† í°í™”í•˜ì—¬ object queryë¥¼ ì¡°ê±´í™”í•˜ëŠ” 1ì°¨ì›ì˜ task tokenì„ ì–»ëŠ”ë‹¤. ì´ëŠ” ê°ê°ì˜ inputì— í•œ task modelì„ ì–»ìŒì„ ì˜ë¯¸í•œë‹¤.
3. Ground truthì— ì¡´ì¬í•˜ëŠ” ê° classì˜ binary maskì˜ ìˆ˜ë¥¼ í‘œí˜„í•˜ëŠ” text listë¥¼ ìƒì„±í•˜ê³  text query í‘œí˜„ì— ë§¤í•‘í•œë‹¤.
    
    â†’ text queryëŠ” imageì™€ taskì— ë”°ë¼ ë‹¬ë¼ì§ˆ ê²ƒ.
    
    ```arduino
    text list : {"ì‚¬ëŒ: 2", "ìë™ì°¨: 1"}
    text query : {â€a photo with a personâ€, â€œa photo with a personâ€, â€œa photo with a carâ€}
    ```
    
4. ëª¨ë¸ì˜ task-dynamic ì˜ˆì¸¡ì„ superviseí•˜ê¸° ìœ„í•´ panoptic ì£¼ì„ì—ì„œ í•´ë‹¹ ground truth ì •ë³´ë¥¼ ë„ì¶œí•œë‹¤.
5. Ground truthëŠ” taskì— ë”°ë¼ ë‹¬ë¼ì§€ë¯€ë¡œ object queryì— task êµ¬ë¶„ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ê°ì²´ì™€ text query ê°„ì˜ query-text contrastive lossë¥¼ ê³„ì‚°í•œë‹¤.
6. Object queryì™€ multi-scale featureëŠ” transformer ë””ì½”ë”ì— ì…ë ¥ë˜ì–´ ìµœì¢… ì˜ˆì¸¡ì„ ìƒì„±í•œë‹¤.

## 3.1 Task Conditioned Joint Training

ê¸°ì¡´ì˜ MaskFormer, Mask2Former, K-Netì€ segmentation, instance, panopticì˜ 3ê°€ì§€ taskì— ëŒ€í•´ ê³µë™ìœ¼ë¡œ í•™ìŠµí•  ê²½ìš° ì„±ëŠ¥ì´ í¬ê²Œ ì €í•˜ëë‹¤. ì¦‰, multi-task ë¬¸ì œë¥¼ í•´ê²°í•˜ì§€ ëª»í–ˆëŠ”ë°, ì´ëŠ” task ì¡°ê±´í™”ê°€ ì—†ê¸° ë•Œë¬¸ì´ë¼ê³  ìƒê°ëœë‹¤.

Multi-task train-once ë¬¸ì œë¥¼ â€˜taskë¡œ ì¡°ê±´í™”ëœ ê³µë™ í•™ìŠµ ì „ëµ(Task Conditioned Joint Training)â€™ì„ ì‚¬ìš©í•˜ì—¬ í•´ê²°í•œë‹¤.

![Untitled](./subpages/3.png)

1. Ground truth ë ˆì´ë¸”ì— ëŒ€í•œ {panoptic, semantic, instance}ì—ì„œ taskë¥¼ ê· ì¼í•˜ê²Œ ìƒ˜í”Œë§í•œ í›„, panoptic ì£¼ì„ì—ì„œ taskë³„ ë ˆì´ë¸”ì„ íŒŒìƒí•˜ì—¬ í•˜ë‚˜ì˜ ì£¼ì„ ì„¸íŠ¸ë§Œ ì‚¬ìš©í•˜ì—¬ panoptic ì£¼ì„ì„ í†µí•©í•œë‹¤.
2. Taskë³„ ground truth ë ˆì´ë¸”ì—ì„œ ì´ë¯¸ì§€ì— ìˆëŠ” ê° classì— ëŒ€í•œ binary mask ì§‘í•©ì„ ì¶”ì¶œí•œë‹¤.
    - Semantic : only one amorphous binary mask
    - Instance : non-overlapping binary mask, only `thing` class, ignoring `stuff`
3. ëª¨ë“  ì§‘í•©ì„ ëŒë©° text list( $T_{list}$ )ë¥¼ {â€a photo with a {CLS}â€} í˜•ì‹ìœ¼ë¡œ ìƒì„±í•œë‹¤. {CLS}ëŠ” class ì´ë¦„ì´ ë“¤ì–´ê°„ë‹¤
4. ìƒ˜í”Œ ë‹¹ binary maskì˜ ìˆ˜ê°€ ë‹¤ë¥´ê¸° ë•Œë¬¸ì—, ì´ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ $T_{list}$ë¥¼ â€œa/an {task} photoâ€ ë¡œ íŒ¨ë”©í•˜ì—¬ ê¸¸ì´ê°€ $N_{text}$ $N_{text}$$T_{pad}$ë¥¼ ì–»ëŠ”ë‹¤. 
    
    â†’ Query-text contrastive lossë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œë„ ì´ $T_{pad}$ë¥¼ ì‚¬ìš©í•œë‹¤. (Sec 3.3)
    

```arduino
// N_textê°€ 5ì¸ ê²½ìš°
T_pad : {
{a photo with a person, 
a photo with a person, 
a photo with a car},
{a phanoptic photo, 
a phanoptic photo}
}
```

í† í°í™”ë˜ê³  task-token (Â $ğ‘„_{task}$ ) ì— ë§¤í•‘ë˜ëŠ”, â€œthe task is {task}â€ í…œí”Œë¦¿ìœ¼ë¡œ êµ¬ì„±ëœ, task input(Â $I_{task}$ )ì„ ì‚¬ìš©í•˜ì—¬ taskì— ëŒ€í•œ ì•„í‚¤í…ì²˜ë¥¼ ì¡°ê±´í™”í•œë‹¤.Â 

â†’ $Q_{task}$ ë¥¼ ì‚¬ìš©í•˜ì—¬ taskì— ëŒ€í•´ OneFormerë¥¼ ì»¨ë””ì…”ë‹í•œë‹¤. (Sec 3.2)

## 3.2 Query Representations

![Untitled](./subpages/4.png)

- Text query ( $Q_{text}$ ): imageì˜ segmentë“¤ì˜ text-based representation
- Object query ( $Q$ ): imageì˜ segmentë“¤ì˜ image-based representation

![Untitled](./subpages/5.png)

$Q_{text}$

$T_{pad}$ í† í°í™” í›„, 6-layer transformerì˜ text-encoderë¥¼ í†µí•´ ì¸ì½”ë”©í•œë‹¤. ì¸ì½”ë”©ëœ $N_{text}$ê°œì˜ ì„ë² ë”©ì€ input imageì˜ â€œbinary maskì˜ ìˆ˜â€ì™€ â€œí•´ë‹¹ maskì˜ classâ€ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. 

$N_{ctx}$ê°œì˜ ì„ë² ë”©ì„ ê°€ì§„ Learnable text context embedding ( $Q_{ctx}$ )ì˜ ì§‘í•©ê³¼, ì¸ì½”ë”©ëœ $N_{text}$ê°œì˜ ì„ë² ë”©ì„ concatí•˜ì—¬ ìµœì¢… $N$ê°œì˜ text query ( $Q_{text}$ ) ë¥¼ ì–»ëŠ”ë‹¤.

â†’ $Q_{ctx}$ëŠ” ìƒ˜í”Œ ì´ë¯¸ì§€ì— ëŒ€í•´ í†µí•©ëœ text contextë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤.  Training ì¤‘ì—ë§Œ text queryë¥¼ ì‚¬ìš©í•˜ë©°, inference ì¤‘ì—ëŠ” text mapper ëª¨ë“ˆì„ ì‚­ì œí•˜ì—¬ ëª¨ë¸ì˜ í¬ê¸°ë¥¼ ì¤„ì¼ ìˆ˜ ìˆë‹¤.

![Untitled](./subpages/6.png)

$Q$

Task token ( $Q_{task}$ ) ì˜ N-1ë²ˆ ë°˜ë³µìœ¼ë¡œ object query $Q'$ì„ ì´ˆê¸°í™”í•œ í›„, 2-layer transformerì˜ flattenëœ 1/4 scaleì˜ feature guidanceì— ë”°ë¼ $Q'$ì„ ì—…ë°ì´íŠ¸í•œë‹¤. ì´ transformerì—ì„œ ì—…ë°ì´íŠ¸ëœ $Q'$ì€ $Q_{task}$ì™€ concatë˜ì–´ Nê°œì˜ queryë“¤ì˜, taskë¡œ ì»¨ë””ì…”ë‹ëœ í‘œí˜„ì¸, $Q$ë¥¼ ì–»ëŠ”ë‹¤.

â†’ All-zeros ë˜ëŠ” random ì´ˆê¸°í™”ì™€ ë‹¬ë¦¬ task ê¸°ë°˜ query ì´ˆê¸°í™”ì™€Â $Q_{task}$ì™€ì˜ concatì€ ëª¨ë¸ì´ ì—¬ëŸ¬ segmentation taskë¥¼ í•™ìŠµí•˜ëŠ” ë° ì¤‘ìš”í•˜ë‹¤. (Sec 4.3)

## 3.3 Task Guided Contrastive Queries

Object query ( $Q$ )ëŠ” taskì— ë”°ë¼ ë‹¤ë¥´ë‹¤.

- Instance: queryëŠ” `thing` í´ë˜ìŠ¤ì—ë§Œ ì§‘ì¤‘í•´ì•¼ í•¨
- Semantic: í•˜ë‚˜ì˜ amorphous object ë§Œ ì˜ˆì¸¡í•´ì•¼ í•¨
- Panoptic: ë‘ê°€ì§€ì˜ í˜¼í•©ì„ ì˜ˆì¸¡í•´ì•¼ í•¨

ê¸°ì¡´ì—ëŠ” ì´ëŸ¬í•œ ì°¨ì´ì ì„ ê³ ë ¤í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ 3ê°€ì§€ task ëª¨ë‘ì—ì„œ í•˜ë‚˜ì˜ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ê²ƒì— ëŒ€í•´ ì‹¤íŒ¨í•œë‹¤.

ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ $Q$ì™€ $Q_{text}$ë¥¼ ì‚¬ìš©í•˜ì—¬ query-text contrastive lossë¥¼ ê³„ì‚°í•œë‹¤.

Sec 3.1ì—ì„œ ì–˜ê¸°í–ˆë“¯ì´, $T_{pad}$ëŠ” ì£¼ì–´ì§„ ì´ë¯¸ì§€ì—ì„œ ê°ì§€ë  ê° maskì— ëŒ€í•œ text í‘œí˜„ listì´ë©°, ê°ì²´ ì—†ìŒì„ ë‚˜íƒ€ë‚´ëŠ” (paddingëœ) â€œa/an {task} photoâ€ê°€ í¬í•¨ëœë‹¤.

ë”°ë¼ì„œ, $Q_{text}$ëŠ” ì´ë¯¸ì§€ì— ì¡´ì¬í•˜ëŠ” object/segmentë¥¼ ë‚˜íƒ€ë‚´ëŠ” $Q$ì˜ ëª©ì ê³¼ ì¼ì¹˜í•œë‹¤.

ì´ ë‘˜ ê°„ì˜ contrastive lossë¥¼ ì‚¬ìš©í•˜ë©´ query í‘œí˜„ì˜ taskê°„ êµ¬ë³„ì„ ì„±ê³µì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆìœ¼ë©°, classê°„ ì°¨ì´ì— ì£¼ì˜ë¥¼ ê¸°ìš¸ì´ê³  category ì˜¤ë¶„ë¥˜ë¥¼ ì¤„ì´ëŠ” íš¨ê³¼ë„ ìˆë‹¤.

$$
{\mathcal L}_{Q \rightarrow Q_{\text{text}}} = -\frac{1}{B} \sum_{i=1}^{B} \log \frac{\exp(q_{i}^{\text{obj}} \odot q_{i}^{\text{txt}} / \tau)}{\sum_{j=1}^{B} \exp(q_{i}^{\text{obj}} \odot q_{j}^{\text{txt}} / \tau)}
$$

$$
{\mathcal L}_{Q_{\text{text}} \rightarrow Q} = -\frac{1}{B} \sum_{i=1}^{B} \log \frac{\exp(q_{i}^{\text{txt}} \odot q_{i}^{\text{obj}} / \tau)}{\sum_{j=1}^{B} \exp(q_{i}^{\text{txt}} \odot q_{j}^{\text{obj}} / \tau)}
$$

$$
{\mathcal L}_{Q \leftrightarrow Q_{\text{text}}} = \mathcal{L}_{Q \rightarrow Q_{\text{text}}} + \mathcal{L}_{Q_{\text{text}} \rightarrow Q}
$$

Bê°œì˜ object-text queryìŒì˜ ë°°ì¹˜ ${(q^{obj}_i,x^{txt}_i)}^B_{i=1}$ê°€ ìˆë‹¤ê³  ê°€ì •í•˜ì. ì—¬ê¸°ì„œ $q^{obj}_i$ì™€ $q^{txt}_i$ëŠ” ê°ê° ië²ˆì§¸ ìŒì˜ $Q$ì™€ $Q_{text}$ì´ë‹¤. Query ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ë‚´ì ì„ ê³„ì‚°í•˜ì—¬ ì¸¡ì •í•œë‹¤. ì „ì²´ contrastive learningì€ ë‘ê°€ì§€ lossë¡œ êµ¬ì„±ëœë‹¤.

- object-to-text contrastive loss: ${L}_{Q \rightarrow Q_{\text{text}}}$
- text-to-object contrastive loss: ${L}_{Q_{\text{text}} \rightarrow Q}$

$\tau$ëŠ” contrastive logitì˜ í¬ê¸°ë¥¼ ì¡°ì •í•˜ê¸° ìœ„í•œ í•™ìŠµê°€ëŠ¥í•œ temperature parameterì´ë‹¤.

## 3.4 Other Architecture Components

### Backbone and Pixel Decoder

Backbone: ImageNetìœ¼ë¡œ ì‚¬ì „ í•™ìŠµëœ backboneì„ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ ì´ë¯¸ì§€ì—ì„œ ë©€í‹°ìŠ¤ì¼€ì¼ featureëŠ” í‘œí˜„ì„ ì¶”ì¶œí•œë‹¤. 

Pixel decoder: Backbone featureë¥¼ ì ì§„ì ìœ¼ë¡œ upsamplingí•˜ì—¬ featureëŠ” ëª¨ë¸ë§ì„ ì§€ì›í•œë‹¤. ìµœê·¼Â multi-scale deformable attentionì˜ ì„±ê³µì— í˜ì…ì–´ pixel decoderì— ë™ì¼í•œ Multi-Scale Deformable Transformer (MSDeformAttn) ê¸°ë°˜ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•œë‹¤.

### Transformer Decoder

Transformer ë””ì½”ë” ë‚´ë¶€ì˜ ê³ í•´ìƒë„ ë§µì„ í™œìš©í•˜ê¸° ìœ„í•´ ë©€í‹°ìŠ¤ì¼€ì¼ ì „ëµì„ ì‚¬ìš©í•œë‹¤.

Input

Object query ( $Q$ )ì™€ pixel decoderì˜ multi-scale output (Â $F_i$ ,Â iâˆˆ{1/4, 1/8, 1/16, 1/32} )ì„ ì…ë ¥ìœ¼ë¡œ ì œê³µí•œë‹¤. 

Process

ì›ë˜ ì´ë¯¸ì§€ì˜ 1/8, 1/16, 1/32 í•´ìƒë„ì˜ featureë¥¼ ì‚¬ìš©í•˜ì—¬ masked cross-Attention (CA) ì—°ì‚°ê³¼ ì´ì–´ì§€ëŠ” self-attention (SA), feed-forward network (FFN)ë¡œÂ $Q$ë¥¼ ì—…ë°ì´íŠ¸í•˜ë©°, transformer ë””ì½”ë” ë‚´ì—ì„œ ì´ëŸ¬í•œ ì—°ì‚°ì„Â $L$ë²ˆ ìˆ˜í–‰í•œë‹¤.

Output

Transformer ë””ì½”ë”ì˜ ìµœì¢… query ì¶œë ¥ì€ í´ë˜ìŠ¤ ì˜ˆì¸¡ì„ ìœ„í•´Â K+1Â ì°¨ì› ê³µê°„ì— ë§¤í•‘ëœë‹¤. ì—¬ê¸°ì„œÂ KëŠ” í´ë˜ìŠ¤ ìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ê³  +1ì€ ê°ì²´ ì—†ìŒ ì˜ˆì¸¡ì„ ë‚˜íƒ€ë‚¸ë‹¤. 

ìµœì¢… ë§ˆìŠ¤í¬ë¥¼ ì–»ê¸° ìœ„í•´Â Qì™€Â F1/4Â ì‚¬ì´ì˜ einsum ì—°ì‚°ì„ ì‚¬ìš©í•˜ì—¬ ì›ë³¸ ì´ë¯¸ì§€ì˜ 1/4 í•´ìƒë„ì—ì„œÂ F1/4ì„ ë””ì½”ë”©í•œë‹¤. inference ì¤‘ì—ëŠ” ìµœì¢… panoptic, semantic, instance segmentation ì˜ˆì¸¡ì„ ì–»ê¸° ìœ„í•´Â Mask2Formerì™€ ë™ì¼í•œ post-processing ê¸°ìˆ ì„ ë”°ë¥¸ë‹¤. ADE20K, Cityscapes, COCO ë°ì´í„°ì…‹ì— ëŒ€í•œ panoptic segmentationì„ ìœ„í•œ post-processing ì¤‘ì— ì„ê³„ê°’ 0.5, 0.8, 0.8ì„ ì´ˆê³¼í•˜ëŠ” ì ìˆ˜ë¡œë§Œ ì˜ˆì¸¡ì„ ìœ ì§€í•œë‹¤.

## 3.5 Losses

Queryì— ëŒ€í•œ contrastive lossì´ì™¸ì—ë„, 

- $\mathcal L_{cls}$ : class ì˜ˆì¸¡ì— ëŒ€í•œ CE-loss
- $\mathcal L_{bce}$ : mask ì˜ˆì¸¡ì— ëŒ€í•œ cross-entropy loss
- $\mathcal L_{dice}$ : mask ì˜ˆì¸¡ì— ëŒ€í•œ dice loss

ë¥¼ ì‚¬ìš©í•œë‹¤.

ë”°ë¼ì„œ ìµœì¢… loss functionì€ 4ê°œ lossì˜ ê°€ì¤‘í•©ì´ë©°, ê°ê°ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì¡ê³ ,

$$
\lambda_{Q \leftrightarrow Q_{\text{text}}} = 0.5, \lambda_{\text{cls}} = 2, \lambda_{\text{bce}} = 5,  \lambda_{\text{dice}} = 5 
$$

ìµœì¢… Lossë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°í–ˆë‹¤.

$$
\mathcal{L}_{\text{final}} = \lambda_{Q \leftrightarrow Q_{\text{text}}} \mathcal{L}_{Q \leftrightarrow Q_{\text{text}}} + \lambda_{\text{cls}} \mathcal{L}_{\text{cls}} + \lambda_{\text{bce}} \mathcal{L}_{\text{bce}} + \lambda_{\text{dice}} \mathcal{L}_{\text{dice}}
$$

Least cost assignmentë¥¼ ì°¾ê¸° ìœ„í•´, ì˜ˆì¸¡ ì§‘í•©ê³¼ ground truth ì‚¬ì´ì˜ bipartite matchingì„ ì‚¬ìš©í•˜ì˜€ë‹¤.

ê°ì²´ ì—†ìŒ ì˜ˆì¸¡ì˜ ê²½ìš°Â $\lambda_{cls}$ë¥¼ 0.1ë¡œ ì„¤ì •í–ˆë‹¤.

# 4. Experiments

## 4.1 Datasets and Evaluation Metrics

### Datasets

- Cityscapes
    - 19 class (11 `stuff` + 8 `thing` )
    - training-set: 2,975
    - validation-set: 500
    - test-set: 1,525
- ADE20K
    - 150 class (50 `stuff` + 100 `thing` )
    - training-set: 20,210
    - validation-set: 2,000
- COCO
    - 133 class (53 `stuff` + 80 `thing` )
    - training-set: 118,000
    - validation-set: 5,000

### Evaluation Metrics

- PQ
- AP
- mIoU

Taskê°€ panopticì¸ ê²½ìš° PQ ì ìˆ˜ë¥¼ ë³´ê³ í•˜ê³  ì‘ì—…ì´ instance ë° semanticì¸ ê²½ìš° ìœ ì‚¬í•˜ê²Œ AP ë° mIoU ì ìˆ˜ë¥¼ ë³´ê³ í•œë‹¤.

## 4.2 Main Results

### ADE20K

![Untitled](./subpages/7.png)

### Cityscapes

![Untitled](./subpages/8.png)

### COCO

![Untitled](./subpages/9.png)

## 4.3 Ablation Studies

### Task-Conditioned Architecture

![Untitled](./subpages/10.png)

### Contrastive Query Loss

![Untitled](./subpages/11.png)

### Input Text Template

![Untitled](./subpages/12.png)

### Task Conditioned Joint Training

![Untitled](./subpages/13.png)

### Task Token Input

![Untitled](./subpages/14.png)

### Reduced Category Misclassifications

![Untitled](./subpages/15.png)

# 5. Conclusion

ë³¸ ì—°êµ¬ì—ì„œëŠ” OneFormerë¼ëŠ” ìƒˆë¡œìš´ multi-task universal image segmentation í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤. Transformerì™€ task-guided queryë¥¼ í†µí•´ semantic, instance, panoptic segmentationì„ ë‹¨ì¼ ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨í•œ ë‹¨ì¼ ëª¨ë¸ë¡œ í†µí•©í•˜ì˜€ë‹¤.

ì´ ëª¨ë¸ì€ 3ê°€ì§€ segmentation ëª¨ë‘ì—ì„œ ì´ì „ì˜ SOTAì¸ Mask2Former ëª¨ë¸ì„ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ë‹¤.

ë˜í•œ, ë‹¨ì¼ ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨í•œ ë‹¨ì¼ ëª¨ë¸ì´ê¸° ë•Œë¬¸ì—, OneFormerëŠ” í›ˆë ¨ ì‹œê°„, ê°€ì¤‘ì¹˜ ì €ì¥ ë° ì¶”ë¡  í˜¸ìŠ¤íŒ… ìš”êµ¬ ì‚¬í•­ì„ 3ë¶„ì˜ 1ë¡œ ì¤„ì¼ ìˆ˜ ìˆì–´ ì´ë¯¸ì§€ ë¶„í• ì„ ë” ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆê²Œ í•œë‹¤.